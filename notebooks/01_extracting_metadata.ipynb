{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN7tPvdqy35JaYOXB4eSj+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shravani018/llm-audit-bench/blob/main/01_extracting_metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 01: Extracting model metadata\n",
        "\n",
        "**Loading 5 small LLMs from HuggingFace, extracting their metadata and architecture for further analysis**"
      ],
      "metadata": {
        "id": "gfeI7RCge34o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "31Gk8BC1d37L"
      },
      "outputs": [],
      "source": [
        "# Downlaoding necessary libraries\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import json\n",
        "import os\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Optional\n",
        "import pandas as pd\n",
        "from transformers import AutoConfig, AutoTokenizer\n",
        "from huggingface_hub import HfApi, ModelCard\n",
        "from huggingface_hub.utils import EntryNotFoundError\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "2oIKhs8UfXDk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMs used\n",
        "models=[\n",
        "    \"gpt2\",\n",
        "    \"distilgpt2\",\n",
        "    \"facebook/opt-125m\",\n",
        "    \"EleutherAI/gpt-neo-125m\",\n",
        "    \"bigscience/bloom-560m\",\n",
        "]"
      ],
      "metadata": {
        "id": "wADAo7KVffHJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining data structure\n",
        "@dataclass\n",
        "class ModelMetadata:\n",
        "    model_id:str\n",
        "    author:str\n",
        "    license:str\n",
        "    has_model_card:bool\n",
        "    architecture:str\n",
        "    num_parameters_estimate:int\n",
        "    num_layers:int\n",
        "    hidden_size:int\n",
        "    num_attention_heads:int\n",
        "    vocab_size:int\n",
        "    max_position_embeddings:int\n",
        "    tokenizer_class:str\n",
        "    tags:list"
      ],
      "metadata": {
        "id": "a-5uk7lXfpkH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing API\n",
        "api = HfApi()"
      ],
      "metadata": {
        "id": "stZqVpJegOsf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the license of a model from its HuggingFace model card metadata\n",
        "def get_license(model_id):\n",
        "    try:\n",
        "        info = api.model_info(model_id)\n",
        "        if info.cardData:\n",
        "            return info.cardData.get(\"license\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None"
      ],
      "metadata": {
        "id": "5BS_ccHsgRCj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the tags associated with a model inorder to understand the framework it uses\n",
        "def get_tags(model_id):\n",
        "    try:\n",
        "        info= api.model_info(model_id)\n",
        "        return list(info.tags or [])\n",
        "    except Exception:\n",
        "        return []"
      ],
      "metadata": {
        "id": "dsuZgm_ZgY0J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for model card as they hold information such as training_data, limitations etc\n",
        "def check_model_card(model_id):\n",
        "    try:\n",
        "        ModelCard.load(model_id)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False"
      ],
      "metadata": {
        "id": "qLw4QBvzgaYc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimates total parameter count from config fields only (no weights downloaded)\n",
        "# Formula: embedding layer (vocab x hidden) + transformer blocks (12 x hidden^2 x layers)\n",
        "def estimate_parameters(config):\n",
        "    h= getattr(config, \"hidden_size\", None) or getattr(config, \"n_embd\", None) or getattr(config, \"d_model\", None)\n",
        "    layers= getattr(config, \"num_hidden_layers\", None) or getattr(config, \"n_layer\", None)\n",
        "    vocab= getattr(config, \"vocab_size\", None)\n",
        "    if h and layers and vocab:\n",
        "        return vocab * h + layers * (12 * h * h)\n",
        "    return None"
      ],
      "metadata": {
        "id": "04oZ4BOqgcGz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the models and extracting metadata\n",
        "def load_model_meta(model_id):\n",
        "    print(f\"loading: {model_id}\")\n",
        "    config = AutoConfig.from_pretrained(model_id)\n",
        "    try:\n",
        "        tok = AutoTokenizer.from_pretrained(model_id)\n",
        "        tokenizer_class = type(tok).__name__\n",
        "    except Exception:\n",
        "        tokenizer_class = None\n",
        "    hidden_size = (\n",
        "        getattr(config, \"hidden_size\", None) or\n",
        "        getattr(config, \"n_embd\", None) or\n",
        "        getattr(config, \"d_model\", None))\n",
        "    num_layers = (\n",
        "        getattr(config, \"num_hidden_layers\", None) or\n",
        "        getattr(config, \"n_layer\", None))\n",
        "    num_heads = (\n",
        "        getattr(config, \"num_attention_heads\", None) or\n",
        "        getattr(config, \"n_head\", None))\n",
        "    max_ctx = (\n",
        "        getattr(config, \"max_position_embeddings\", None) or\n",
        "        getattr(config, \"n_positions\", None))\n",
        "    meta=ModelMetadata(\n",
        "        model_id= model_id,\n",
        "        author= model_id.split(\"/\")[0] if \"/\" in model_id else \"openai\",\n",
        "        license= get_license(model_id),\n",
        "        has_model_card= check_model_card(model_id),\n",
        "        architecture= config.architectures[0] if config.architectures else None,\n",
        "        num_parameters_estimate= estimate_parameters(config),\n",
        "        num_layers= num_layers,\n",
        "        hidden_size= hidden_size,\n",
        "        num_attention_heads= num_heads,\n",
        "        vocab_size= getattr(config, \"vocab_size\", None),\n",
        "        max_position_embeddings= max_ctx,\n",
        "        tokenizer_class= tokenizer_class,\n",
        "        tags= get_tags(model_id))\n",
        "    return meta"
      ],
      "metadata": {
        "id": "OiU8IKu4gjj8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_models = [load_model_meta(m) for m in models]\n",
        "print(f\"done. loaded {len(all_models)} models.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwoA2XeKgntL",
        "outputId": "d05b6c23-2443-4fd4-c648-cfb91083008e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading: gpt2\n",
            "loading: distilgpt2\n",
            "loading: facebook/opt-125m\n",
            "loading: EleutherAI/gpt-neo-125m\n",
            "loading: bigscience/bloom-560m\n",
            "done. loaded 5 models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing data inorder to export it\n",
        "rows=[]\n",
        "for model in all_models:\n",
        "  rows.append({\n",
        "        \"model_id\":model.model_id,\n",
        "        \"architecture\":model.architecture,\n",
        "        \"params_estimate\": f\"{model.num_parameters_estimate:,}\" if model.num_parameters_estimate else \"N/A\",\n",
        "        \"layers\":model.num_layers,\n",
        "        \"hidden_size\":model.hidden_size,\n",
        "        \"attn_heads\":model.num_attention_heads,\n",
        "        \"vocab_size\":model.vocab_size,\n",
        "        \"max_ctx\":model.max_position_embeddings,\n",
        "        \"tokenizer\":model.tokenizer_class,\n",
        "        \"license\":model.license,\n",
        "        \"model_card\":model.has_model_card,\n",
        "    })"
      ],
      "metadata": {
        "id": "uM1RO5MPhbHP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df=pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "fxDut7UGhjY8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "jP8QSddyiCWN",
        "outputId": "1ebed3f2-94b9-4bc3-ef75-e0b42bfb3da3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  model_id       architecture params_estimate  layers  \\\n",
              "0                     gpt2    GPT2LMHeadModel     123,532,032      12   \n",
              "1               distilgpt2    GPT2LMHeadModel      81,064,704       6   \n",
              "2        facebook/opt-125m     OPTForCausalLM     123,543,552      12   \n",
              "3  EleutherAI/gpt-neo-125m  GPTNeoForCausalLM     123,532,032      12   \n",
              "4    bigscience/bloom-560m   BloomForCausalLM     558,891,008      24   \n",
              "\n",
              "   hidden_size  attn_heads  vocab_size  max_ctx           tokenizer  \\\n",
              "0          768          12       50257   1024.0   GPT2TokenizerFast   \n",
              "1          768          12       50257   1024.0   GPT2TokenizerFast   \n",
              "2          768          12       50272   2048.0   GPT2TokenizerFast   \n",
              "3          768          12       50257   2048.0   GPT2TokenizerFast   \n",
              "4         1024          16      250880      NaN  BloomTokenizerFast   \n",
              "\n",
              "                     license  model_card  \n",
              "0                        mit        True  \n",
              "1                 apache-2.0        True  \n",
              "2                      other        True  \n",
              "3                        mit        True  \n",
              "4  bigscience-bloom-rail-1.0        True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7227e33d-f496-4b27-a901-1ec0238df340\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_id</th>\n",
              "      <th>architecture</th>\n",
              "      <th>params_estimate</th>\n",
              "      <th>layers</th>\n",
              "      <th>hidden_size</th>\n",
              "      <th>attn_heads</th>\n",
              "      <th>vocab_size</th>\n",
              "      <th>max_ctx</th>\n",
              "      <th>tokenizer</th>\n",
              "      <th>license</th>\n",
              "      <th>model_card</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gpt2</td>\n",
              "      <td>GPT2LMHeadModel</td>\n",
              "      <td>123,532,032</td>\n",
              "      <td>12</td>\n",
              "      <td>768</td>\n",
              "      <td>12</td>\n",
              "      <td>50257</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>GPT2TokenizerFast</td>\n",
              "      <td>mit</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>distilgpt2</td>\n",
              "      <td>GPT2LMHeadModel</td>\n",
              "      <td>81,064,704</td>\n",
              "      <td>6</td>\n",
              "      <td>768</td>\n",
              "      <td>12</td>\n",
              "      <td>50257</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>GPT2TokenizerFast</td>\n",
              "      <td>apache-2.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>facebook/opt-125m</td>\n",
              "      <td>OPTForCausalLM</td>\n",
              "      <td>123,543,552</td>\n",
              "      <td>12</td>\n",
              "      <td>768</td>\n",
              "      <td>12</td>\n",
              "      <td>50272</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>GPT2TokenizerFast</td>\n",
              "      <td>other</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EleutherAI/gpt-neo-125m</td>\n",
              "      <td>GPTNeoForCausalLM</td>\n",
              "      <td>123,532,032</td>\n",
              "      <td>12</td>\n",
              "      <td>768</td>\n",
              "      <td>12</td>\n",
              "      <td>50257</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>GPT2TokenizerFast</td>\n",
              "      <td>mit</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bigscience/bloom-560m</td>\n",
              "      <td>BloomForCausalLM</td>\n",
              "      <td>558,891,008</td>\n",
              "      <td>24</td>\n",
              "      <td>1024</td>\n",
              "      <td>16</td>\n",
              "      <td>250880</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BloomTokenizerFast</td>\n",
              "      <td>bigscience-bloom-rail-1.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7227e33d-f496-4b27-a901-1ec0238df340')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7227e33d-f496-4b27-a901-1ec0238df340 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7227e33d-f496-4b27-a901-1ec0238df340');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_4a41a9cf-1682-48f2-ba81-9c1df6714752\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('meta_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4a41a9cf-1682-48f2-ba81-9c1df6714752 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('meta_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "meta_df",
              "summary": "{\n  \"name\": \"meta_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"model_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"distilgpt2\",\n          \"bigscience/bloom-560m\",\n          \"facebook/opt-125m\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"architecture\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"OPTForCausalLM\",\n          \"BloomForCausalLM\",\n          \"GPT2LMHeadModel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_estimate\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"81,064,704\",\n          \"558,891,008\",\n          \"123,532,032\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"layers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 6,\n        \"max\": 24,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          12,\n          6,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hidden_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 114,\n        \"min\": 768,\n        \"max\": 1024,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1024,\n          768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attn_heads\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 12,\n        \"max\": 16,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          16,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vocab_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 89719,\n        \"min\": 50257,\n        \"max\": 250880,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          50257,\n          50272\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_ctx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 591.2066756501767,\n        \"min\": 1024.0,\n        \"max\": 2048.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2048.0,\n          1024.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"BloomTokenizerFast\",\n          \"GPT2TokenizerFast\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"license\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"apache-2.0\",\n          \"bigscience-bloom-rail-1.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_card\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"./results\",exist_ok=True)\n",
        "with open(\"./results/model_metadata.json\",\"w\") as f:\n",
        "    json.dump({\"./results/models\": [asdict(m) for m in all_models]}, f, indent=2)"
      ],
      "metadata": {
        "id": "yEHa3IWAiEWy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next: 02_transparency.ipynb\n",
        "\n",
        "Scoring each model's transparency."
      ],
      "metadata": {
        "id": "3rDkchu9k6HR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y0K2TptClHg4"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}