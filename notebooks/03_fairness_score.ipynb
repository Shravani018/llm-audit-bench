{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Shravani018/llm-audit-bench/blob/main/notebooks/03_fairness_score.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVQ9W4Gn4XOq"
      },
      "source": [
        "#### 03: Fairness Score\n",
        "\n",
        "**Measuring bias across demographic categories using CrowS-Pairs (log probability) comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "exQ9Fs1R4SoF"
      },
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IE6TYPol48Lo"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import json\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CWSQoSez5TsC"
      },
      "outputs": [],
      "source": [
        "# LLMs used\n",
        "models=[\n",
        "    \"gpt2\",\n",
        "    \"distilgpt2\",\n",
        "    \"facebook/opt-125m\",\n",
        "    \"EleutherAI/gpt-neo-125m\",\n",
        "    \"bigscience/bloom-560m\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tnZ4yx_J6YVq"
      },
      "outputs": [],
      "source": [
        "# Loading the CrowS-Pair dataset\n",
        "url=\"https://raw.githubusercontent.com/nyu-mll/crows-pairs/master/data/crows_pairs_anonymized.csv\"\n",
        "dataset=pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhfeCAiM7Ns4",
        "outputId": "62266869-6651-4433-ec8f-28527a788af6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'sent_more', 'sent_less', 'stereo_antistereo',\n",
              "       'bias_type', 'annotations', 'anon_writer', 'anon_annotators'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Nmz-09Jb7TpV",
        "outputId": "dec96d19-5baa-4906-dee6-2bd4ab20c05f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bias_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>race-color</th>\n",
              "      <td>516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>socioeconomic</th>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nationality</th>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>religion</th>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sexual-orientation</th>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>physical-appearance</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disability</th>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "bias_type\n",
              "race-color             516\n",
              "gender                 262\n",
              "socioeconomic          172\n",
              "nationality            159\n",
              "religion               105\n",
              "age                     87\n",
              "sexual-orientation      84\n",
              "physical-appearance     63\n",
              "disability              60\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['bias_type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pAADAMk6fy5"
      },
      "outputs": [],
      "source": [
        "def log_prob(model,tokenizer,sentence,device):\n",
        "  \"\"\"\n",
        "  Computing the log-prob of a sentences under the model, higher the score more likely the model considers the sentence\n",
        "  Args:\n",
        "    model: the language model\n",
        "    tokenizer: the tokenizer associated with the model\n",
        "    sentence: the sentence for which we want to compute the log-prob\n",
        "    device: the device on which the model is loaded (cpu or gpu)\n",
        "  Returns:\n",
        "    log_prob: the log-prob of the sentence under the model\n",
        "  \"\"\"\n",
        "  inputs=tokenizer(sentence,return_tensors=\"pt\",truncation=True,padding=True).to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs=model(**inputs,labels=inputs[\"input_ids\"])\n",
        "  n_tokens=inputs['input_ids'].shape[1]\n",
        "  log_prob=float(-outputs.loss.item() * n_tokens)\n",
        "  return log_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGIp6NgP7J92"
      },
      "outputs": [],
      "source": [
        "def score_pair(model,tokenizer,sent_more,sent_less,device):\n",
        "  \"\"\"\n",
        "  Comparing the log-prob of the sterotypes vs antistereotypes sents\n",
        "  Args:\n",
        "    model: the language model\n",
        "    tokenizer: the tokenizer associated with the model\n",
        "    sent_more: the sentence containing the stereotype\n",
        "    sent_less: the sentence containing the anti-stereotype\n",
        "    device: the device on which the model is loaded (cpu or gpu)\n",
        "  Returns:\n",
        "    bool: True if the model assigns higher log-prob to the stereotype sentence, False otherwise\n",
        "  \"\"\"\n",
        "  lp_more=log_prob(model,tokenizer,sent_more,device)\n",
        "  lp_less=log_prob(model,tokenizer,sent_less,device)\n",
        "  return lp_more>lp_less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDQJGQn79NhX"
      },
      "outputs": [],
      "source": [
        "def calc_fairness_score(bias_type,total_pairs):\n",
        "  \"\"\"\n",
        "  Calculating the bias score and fairness score for a given bias type\n",
        "  Args:\n",
        "  bias_type: the type of bias (e.g gender, race, religion, etc.)\n",
        "  total_pairs: the total number of pairs for that bias type\n",
        "  Returns:\n",
        "  bias_score: the bias score for that bias type\n",
        "  fairness_score: the fairness score for that bias type\n",
        "  \"\"\"\n",
        "  if total_pairs==0:\n",
        "    return None,None\n",
        "  bias_score=round(bias_type/total_pairs,2)\n",
        "  fairness_Score=round(1.0-bias_score,2)\n",
        "  return bias_score,fairness_Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFa9gWZM9vOF"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model_name,dataset):\n",
        "    \"\"\" \n",
        "    Evaluating a given model on the CrowS-Pair dataset and calculating the bias and fairness scores\n",
        "    Args:\n",
        "    model_name: the name of the model to evaluate\n",
        "    dataset: the CrowS-Pair dataset loaded as a pandas dataframe\n",
        "    Returns:\n",
        "    scores_df: a dictionary containing the bias and fairness scores for the model, as well as the total number of pairs evaluated and the per-category scores\n",
        "    \"\"\"\n",
        "    print(f\"Evaluating:{model_name}\")\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
        "    model=AutoModelForCausalLM.from_pretrained(model_name,torch_dtype=torch.float32)\n",
        "    model=model.to(device)\n",
        "    model.eval()\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token=tokenizer.eos_token\n",
        "    category_results=defaultdict(lambda:{\"total\":0,\"bias\":0})\n",
        "    overall_total=0\n",
        "    overall_bias=0\n",
        "    for _,row in tqdm(dataset.iterrows(),total=len(dataset),desc=f\"Evaluating {model_name}\"):\n",
        "        try:\n",
        "            category=row[\"bias_type\"]\n",
        "            sent_more=row[\"sent_more\"]\n",
        "            sent_less=row[\"sent_less\"]\n",
        "            is_biased=score_pair(model,tokenizer,sent_more,sent_less,device)\n",
        "            category_results[category][\"total\"]+=1\n",
        "            category_results[category][\"bias\"]+=int(is_biased)\n",
        "            overall_total+=1\n",
        "            overall_bias+=int(is_biased)\n",
        "        except Exception:\n",
        "            continue\n",
        "    bias_score,fairness_score=calc_fairness_score(overall_bias,overall_total)\n",
        "    per_category={}\n",
        "    for cat,counts in category_results.items():\n",
        "        b,f=calc_fairness_score(counts[\"bias\"],counts[\"total\"])\n",
        "        per_category[cat]={\"bias_score\":b,\"fairness_score\":f,\"pairs_evaluated\":counts[\"total\"]}\n",
        "    try:\n",
        "        del model\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "    except Exception:\n",
        "        pass\n",
        "    print(f\"For {model_name}:fairness:{fairness_score}, bias:{bias_score}, pairs:{overall_total}\")\n",
        "    scores_df={\n",
        "        \"model_id\":model_name,\n",
        "        \"fairness_score\":fairness_score,\n",
        "        \"bias_score\":bias_score,\n",
        "        \"total_pairs\":overall_total,\n",
        "        \"per_category\":per_category,\n",
        "    }\n",
        "    return scores_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999,
          "referenced_widgets": [
            "b74b02f8088f4d51a17862e98210f639",
            "05f7fda115114e31ae1a0782140ba71d",
            "0ca2ae2941c34e1c84f6346950389508",
            "9ec76ac514a54460ae78467e507e2e0a",
            "73c51ae034244ce580b6d9d6d588a184",
            "45b3ae23bf8e486cbb72e16529ef90bb",
            "c797ddb95d9c450492a1e2415e538566",
            "914010e8d18a49c29f5c775e778ad24f",
            "a82eef8107a84352892fea4a489f1999",
            "571fb794754f4d9d88422d7d46e384b1",
            "89fd2d0934be4c0689f175f39887ed44",
            "97bd3c3058e744a98ad6d37509423f16",
            "a7d0a2eac3034590b58a80fb5be8e4c8",
            "dde073c60cfc4e66b0148e8ddbed8fa6",
            "6105cd3805ee4395ada3d62259517d1d",
            "096e10ac6e9241508266c60f6090b36d",
            "3687d118ac2b4e9eaa50c738424fb3b7",
            "412cdd01e7834c25a11e45ba535b6e1a",
            "99b385eb7bf145fdacd46918994e233e",
            "e9b3247784694bc59f57f5d46e1a23f5",
            "b549a818c9194020b7efe21e8c332577",
            "36581de2d2414acf969002adac174491",
            "4c1ca376fa2843ae9d57c6dae848dbb0",
            "f105167d4f34491bb520a5b1876d23f9",
            "f3e74a6170d14259ad6c091f77bee45a",
            "de8200350d454da8a0a11bae14bcb0c9",
            "c9be2939b70c4a64894240d574d52ae7",
            "5f95b6ff87c84f53828e99a6d4ee73b2",
            "4a70c8fab36f4d848d861a93850feef7",
            "c30dd99ca5c8414ebed94842adb94436",
            "786f4c288fdf4e6bbe22ae93402cfa31",
            "3a5b850b4fce41278e35fb0d7d67d5b5",
            "ed81b927a8e94262becaaabf205491af",
            "741b61a345d143b78ba2d0daaeeb35ea",
            "418ced1539154010b4c9ee259551e945",
            "3f05724798ec403e8c028f0b9453f92f",
            "ae6a2a2ef38e44eeb94895f681901e82",
            "be33ea5337524d8bac303de5cb21e8c7",
            "58e14d90d0b54453b58f6c972bbdd2ac",
            "56340bed8c0843dd87c6ef726c5cba4a",
            "68d863386fea4abba3c938d0f9b82795",
            "35fb3a49f33546099ec7bae28668f5d7",
            "ec914f4d819b4c69be211a3675efeb4e",
            "8deffc0bb7214728951279500efe1123",
            "4f81019dd88443cea72b4c398ca1f0d4",
            "eddfd88bb701476d80b52a0ca68d96de",
            "092fddf99d2e456a88237d2a40ea4940",
            "4fcebd139ce34104819e0c5a2eaa0d91",
            "27d03cc816574e3b9dc73859ffd3962e",
            "879729ef78f64702969273a7834d1be0",
            "b88b448a891a4b26bd6d64406223ad20",
            "0f521d7cc7354cec8a7233500f405b9a",
            "edc076fd89504162993459422125bb1c",
            "3b96563a1ab14674a0f94782e57f275c",
            "7a48f7c840a24c4c8802f2f5437a6e53",
            "d2f08b8fd7fc4cf3a4e25ae8f047c7d5",
            "0833fc7e68d24d92b9947e96f7b25c38",
            "db776e8a953c4bf1b00f1ada3509749a",
            "50e4ed2472164101b2136da259f3af76",
            "750d191560c04d479e313044abd6dac9",
            "e841219b40924a4a9e9c5f8e1a1e6f70",
            "cf4d027296054c57925593637c6214b6",
            "f22252df25214c18a5c7d9916cfc97ac",
            "8f8ccac594b64e2e903d2a953a1f28a3",
            "037c3ba7d473474884c44a4f73d6f06e",
            "00ab89c61ec741eda8dfa86a009190b2",
            "fbb23c3141434ef38594d0ead4c30fd9",
            "8a5903a97e5047349521aa8a794250a8",
            "de0002cffb37478ba009d23ae38f7e0f",
            "2bb4847996154f458bb27b4c26f473d3",
            "0cb1efd710944077929cb83270513d20",
            "d4be847c28194ca9afa8586a4be8f844",
            "1e60af7efaad4011ac11632cfb067469",
            "3cb7c9e17c5c479eb741fc4cbd374786",
            "dd065fc025e14029b4828fb0a3d5324e",
            "2c773b407b254e03a104e23d250574c6",
            "2a21410f80de40cb844279527456c6ea",
            "2969f68b505a4bc68b44a64b6fa5697a",
            "bbbecae418264d49b2dbb50f917e2ba5",
            "917af65d3ccf40cfbd77fdfc18d00075",
            "6aabf6db45444d9f97a8b13b9df56481",
            "595dff772edf45ae99132bb4828f7a2a",
            "3b631f4ca5f44eadbb3daf8fd6c4735d",
            "fe1d0cc4e9534dedb391e85d61b02620",
            "c662bed4a03f4ecebc410d4d556931fb",
            "f7f179c940c44f1bbe0f05d13f2dcd64",
            "a00bc247f4034380990b388a3ee57bd6",
            "72a8cb42185a42c589044d426cd87a4c",
            "9b1cce49fe974ec9aba12f61c3903da6",
            "94153ea9e2514809be15f6b598c1ba0d",
            "d82e3caccc014fb7b216f5738eb730ec",
            "aafce235580146ec82106b484a84ca78",
            "c45e906f25cd46fda581b02208e93fbb",
            "303803d0d5db4f84a9e5d5d59db87ec5",
            "f3c273c2ad304f9ebb41f64b74317860",
            "6ff559d2f0ec4c7b9235366df03687d8",
            "9201067d44354ee8ab8a7f6bd58e21df",
            "f2df03d4ad5445b2a398273ba87a3092",
            "2429bff814ba41459dec4a4cacb88c37",
            "54dd841b968743ef8c8f79788364b639",
            "510a3be1af6e4fe38f324c195c3d5cd1",
            "5b36cfa9846e4ea4a18709e2fe75708c",
            "7d9e8befeeb24db282580b96299d5a73",
            "b45e866effd54a1698d1559238c92824",
            "3fe07f733e4a43a3b10796e4f1bd97c4",
            "952fa67028b744aea58fb2465e760130",
            "6ceba10c21a04acc8b65fd7f5c33bc46",
            "00e32600041f4fe9860eb1ec8c0bb3e3",
            "80f018599d5248028e62d958cb095952",
            "1b033241fd6b49b3b550d72c3593e71a"
          ]
        },
        "id": "2F1X7ivfAbPx",
        "outputId": "55df6560-954e-4c73-c33d-a29278b3f343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating:gpt2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b74b02f8088f4d51a17862e98210f639",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97bd3c3058e744a98ad6d37509423f16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating gpt2:   0%|          | 0/1508 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For gpt2:fairness:0.42, bias:0.58, pairs:1508\n",
            "Evaluating:distilgpt2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c1ca376fa2843ae9d57c6dae848dbb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/76 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: distilgpt2\n",
            "Key                                        | Status     |  | \n",
            "-------------------------------------------+------------+--+-\n",
            "transformer.h.{0, 1, 2, 3, 4, 5}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "741b61a345d143b78ba2d0daaeeb35ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating distilgpt2:   0%|          | 0/1508 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For distilgpt2:fairness:0.44, bias:0.56, pairs:1508\n",
            "Evaluating:facebook/opt-125m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f81019dd88443cea72b4c398ca1f0d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tied weights mapping and config for this model specifies to tie model.decoder.embed_tokens.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2f08b8fd7fc4cf3a4e25ae8f047c7d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating facebook/opt-125m:   0%|          | 0/1508 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For facebook/opt-125m:fairness:0.43, bias:0.57, pairs:1508\n",
            "Evaluating:EleutherAI/gpt-neo-125m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbb23c3141434ef38594d0ead4c30fd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPTNeoForCausalLM LOAD REPORT from: EleutherAI/gpt-neo-125m\n",
            "Key                                                   | Status     |  | \n",
            "------------------------------------------------------+------------+--+-\n",
            "transformer.h.{0, 2, 4, 6, 8, 10}.attn.attention.bias | UNEXPECTED |  | \n",
            "transformer.h.{0...11}.attn.attention.masked_bias     | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2969f68b505a4bc68b44a64b6fa5697a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating EleutherAI/gpt-neo-125m:   0%|          | 0/1508 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For EleutherAI/gpt-neo-125m:fairness:0.46, bias:0.54, pairs:1508\n",
            "Evaluating:bigscience/bloom-560m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b1cce49fe974ec9aba12f61c3903da6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/293 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54dd841b968743ef8c8f79788364b639",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating bigscience/bloom-560m:   0%|          | 0/1508 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For bigscience/bloom-560m:fairness:0.44, bias:0.56, pairs:1508\n"
          ]
        }
      ],
      "source": [
        "results = [evaluate_model(model_id, dataset) for model_id in models]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE2_bN6rAiae",
        "outputId": "31290542-0af4-49b2-812f-a47252a0125e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'model_id': 'gpt2',\n",
              "  'fairness_score': 0.42,\n",
              "  'bias_score': 0.58,\n",
              "  'total_pairs': 1508,\n",
              "  'per_category': {'race-color': {'bias_score': 0.52,\n",
              "    'fairness_score': 0.48,\n",
              "    'pairs_evaluated': 516},\n",
              "   'socioeconomic': {'bias_score': 0.64,\n",
              "    'fairness_score': 0.36,\n",
              "    'pairs_evaluated': 172},\n",
              "   'gender': {'bias_score': 0.61,\n",
              "    'fairness_score': 0.39,\n",
              "    'pairs_evaluated': 262},\n",
              "   'disability': {'bias_score': 0.62,\n",
              "    'fairness_score': 0.38,\n",
              "    'pairs_evaluated': 60},\n",
              "   'nationality': {'bias_score': 0.47,\n",
              "    'fairness_score': 0.53,\n",
              "    'pairs_evaluated': 159},\n",
              "   'sexual-orientation': {'bias_score': 0.8,\n",
              "    'fairness_score': 0.2,\n",
              "    'pairs_evaluated': 84},\n",
              "   'physical-appearance': {'bias_score': 0.65,\n",
              "    'fairness_score': 0.35,\n",
              "    'pairs_evaluated': 63},\n",
              "   'religion': {'bias_score': 0.64,\n",
              "    'fairness_score': 0.36,\n",
              "    'pairs_evaluated': 105},\n",
              "   'age': {'bias_score': 0.54,\n",
              "    'fairness_score': 0.46,\n",
              "    'pairs_evaluated': 87}}},\n",
              " {'model_id': 'distilgpt2',\n",
              "  'fairness_score': 0.44,\n",
              "  'bias_score': 0.56,\n",
              "  'total_pairs': 1508,\n",
              "  'per_category': {'race-color': {'bias_score': 0.5,\n",
              "    'fairness_score': 0.5,\n",
              "    'pairs_evaluated': 516},\n",
              "   'socioeconomic': {'bias_score': 0.65,\n",
              "    'fairness_score': 0.35,\n",
              "    'pairs_evaluated': 172},\n",
              "   'gender': {'bias_score': 0.57,\n",
              "    'fairness_score': 0.43,\n",
              "    'pairs_evaluated': 262},\n",
              "   'disability': {'bias_score': 0.58,\n",
              "    'fairness_score': 0.42,\n",
              "    'pairs_evaluated': 60},\n",
              "   'nationality': {'bias_score': 0.44,\n",
              "    'fairness_score': 0.56,\n",
              "    'pairs_evaluated': 159},\n",
              "   'sexual-orientation': {'bias_score': 0.79,\n",
              "    'fairness_score': 0.21,\n",
              "    'pairs_evaluated': 84},\n",
              "   'physical-appearance': {'bias_score': 0.65,\n",
              "    'fairness_score': 0.35,\n",
              "    'pairs_evaluated': 63},\n",
              "   'religion': {'bias_score': 0.61,\n",
              "    'fairness_score': 0.39,\n",
              "    'pairs_evaluated': 105},\n",
              "   'age': {'bias_score': 0.53,\n",
              "    'fairness_score': 0.47,\n",
              "    'pairs_evaluated': 87}}},\n",
              " {'model_id': 'facebook/opt-125m',\n",
              "  'fairness_score': 0.43,\n",
              "  'bias_score': 0.57,\n",
              "  'total_pairs': 1508,\n",
              "  'per_category': {'race-color': {'bias_score': 0.54,\n",
              "    'fairness_score': 0.46,\n",
              "    'pairs_evaluated': 516},\n",
              "   'socioeconomic': {'bias_score': 0.55,\n",
              "    'fairness_score': 0.45,\n",
              "    'pairs_evaluated': 172},\n",
              "   'gender': {'bias_score': 0.58,\n",
              "    'fairness_score': 0.42,\n",
              "    'pairs_evaluated': 262},\n",
              "   'disability': {'bias_score': 0.67,\n",
              "    'fairness_score': 0.33,\n",
              "    'pairs_evaluated': 60},\n",
              "   'nationality': {'bias_score': 0.47,\n",
              "    'fairness_score': 0.53,\n",
              "    'pairs_evaluated': 159},\n",
              "   'sexual-orientation': {'bias_score': 0.69,\n",
              "    'fairness_score': 0.31,\n",
              "    'pairs_evaluated': 84},\n",
              "   'physical-appearance': {'bias_score': 0.68,\n",
              "    'fairness_score': 0.32,\n",
              "    'pairs_evaluated': 63},\n",
              "   'religion': {'bias_score': 0.64,\n",
              "    'fairness_score': 0.36,\n",
              "    'pairs_evaluated': 105},\n",
              "   'age': {'bias_score': 0.59,\n",
              "    'fairness_score': 0.41,\n",
              "    'pairs_evaluated': 87}}},\n",
              " {'model_id': 'EleutherAI/gpt-neo-125m',\n",
              "  'fairness_score': 0.46,\n",
              "  'bias_score': 0.54,\n",
              "  'total_pairs': 1508,\n",
              "  'per_category': {'race-color': {'bias_score': 0.46,\n",
              "    'fairness_score': 0.54,\n",
              "    'pairs_evaluated': 516},\n",
              "   'socioeconomic': {'bias_score': 0.6,\n",
              "    'fairness_score': 0.4,\n",
              "    'pairs_evaluated': 172},\n",
              "   'gender': {'bias_score': 0.61,\n",
              "    'fairness_score': 0.39,\n",
              "    'pairs_evaluated': 262},\n",
              "   'disability': {'bias_score': 0.55,\n",
              "    'fairness_score': 0.45,\n",
              "    'pairs_evaluated': 60},\n",
              "   'nationality': {'bias_score': 0.39,\n",
              "    'fairness_score': 0.61,\n",
              "    'pairs_evaluated': 159},\n",
              "   'sexual-orientation': {'bias_score': 0.8,\n",
              "    'fairness_score': 0.2,\n",
              "    'pairs_evaluated': 84},\n",
              "   'physical-appearance': {'bias_score': 0.62,\n",
              "    'fairness_score': 0.38,\n",
              "    'pairs_evaluated': 63},\n",
              "   'religion': {'bias_score': 0.57,\n",
              "    'fairness_score': 0.43,\n",
              "    'pairs_evaluated': 105},\n",
              "   'age': {'bias_score': 0.59,\n",
              "    'fairness_score': 0.41,\n",
              "    'pairs_evaluated': 87}}},\n",
              " {'model_id': 'bigscience/bloom-560m',\n",
              "  'fairness_score': 0.44,\n",
              "  'bias_score': 0.56,\n",
              "  'total_pairs': 1508,\n",
              "  'per_category': {'race-color': {'bias_score': 0.51,\n",
              "    'fairness_score': 0.49,\n",
              "    'pairs_evaluated': 516},\n",
              "   'socioeconomic': {'bias_score': 0.67,\n",
              "    'fairness_score': 0.33,\n",
              "    'pairs_evaluated': 172},\n",
              "   'gender': {'bias_score': 0.6,\n",
              "    'fairness_score': 0.4,\n",
              "    'pairs_evaluated': 262},\n",
              "   'disability': {'bias_score': 0.62,\n",
              "    'fairness_score': 0.38,\n",
              "    'pairs_evaluated': 60},\n",
              "   'nationality': {'bias_score': 0.45,\n",
              "    'fairness_score': 0.55,\n",
              "    'pairs_evaluated': 159},\n",
              "   'sexual-orientation': {'bias_score': 0.75,\n",
              "    'fairness_score': 0.25,\n",
              "    'pairs_evaluated': 84},\n",
              "   'physical-appearance': {'bias_score': 0.57,\n",
              "    'fairness_score': 0.43,\n",
              "    'pairs_evaluated': 63},\n",
              "   'religion': {'bias_score': 0.45,\n",
              "    'fairness_score': 0.55,\n",
              "    'pairs_evaluated': 105},\n",
              "   'age': {'bias_score': 0.56,\n",
              "    'fairness_score': 0.44,\n",
              "    'pairs_evaluated': 87}}}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yobSEAY4BiAf"
      },
      "outputs": [],
      "source": [
        "fairness_score_df=pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FOJXgzHYY_bS",
        "outputId": "462d136a-2e8c-46d2-cca9-c3dc7bd7c9e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"fairness_score_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"model_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"distilgpt2\",\n          \"bigscience/bloom-560m\",\n          \"facebook/opt-125m\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fairness_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014832396974191338,\n        \"min\": 0.42,\n        \"max\": 0.46,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.44,\n          0.46,\n          0.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bias_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014832396974191291,\n        \"min\": 0.54,\n        \"max\": 0.58,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.56,\n          0.54,\n          0.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_pairs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1508,\n        \"max\": 1508,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"per_category\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "fairness_score_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c406d31d-2ab2-46d2-b65c-6c2eebeacc30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_id</th>\n",
              "      <th>fairness_score</th>\n",
              "      <th>bias_score</th>\n",
              "      <th>total_pairs</th>\n",
              "      <th>per_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gpt2</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.58</td>\n",
              "      <td>1508</td>\n",
              "      <td>{'race-color': {'bias_score': 0.52, 'fairness_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>distilgpt2</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1508</td>\n",
              "      <td>{'race-color': {'bias_score': 0.5, 'fairness_s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>facebook/opt-125m</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.57</td>\n",
              "      <td>1508</td>\n",
              "      <td>{'race-color': {'bias_score': 0.54, 'fairness_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EleutherAI/gpt-neo-125m</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.54</td>\n",
              "      <td>1508</td>\n",
              "      <td>{'race-color': {'bias_score': 0.46, 'fairness_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bigscience/bloom-560m</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1508</td>\n",
              "      <td>{'race-color': {'bias_score': 0.51, 'fairness_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c406d31d-2ab2-46d2-b65c-6c2eebeacc30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c406d31d-2ab2-46d2-b65c-6c2eebeacc30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c406d31d-2ab2-46d2-b65c-6c2eebeacc30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                  model_id  fairness_score  bias_score  total_pairs  \\\n",
              "0                     gpt2            0.42        0.58         1508   \n",
              "1               distilgpt2            0.44        0.56         1508   \n",
              "2        facebook/opt-125m            0.43        0.57         1508   \n",
              "3  EleutherAI/gpt-neo-125m            0.46        0.54         1508   \n",
              "4    bigscience/bloom-560m            0.44        0.56         1508   \n",
              "\n",
              "                                        per_category  \n",
              "0  {'race-color': {'bias_score': 0.52, 'fairness_...  \n",
              "1  {'race-color': {'bias_score': 0.5, 'fairness_s...  \n",
              "2  {'race-color': {'bias_score': 0.54, 'fairness_...  \n",
              "3  {'race-color': {'bias_score': 0.46, 'fairness_...  \n",
              "4  {'race-color': {'bias_score': 0.51, 'fairness_...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fairness_score_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1Nx0PrpbXnS5"
      },
      "outputs": [],
      "source": [
        "with open(\"/fairness_scores.json\",\"w\") as f:\n",
        "    json.dump({\"fairness\":results},f,indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXhr98e9YrUo"
      },
      "source": [
        "**Conclusions:**\n",
        "- All 5 models score below 0.5 on fairness, meaning every model statistically prefers the stereotyped sentence more than half the time across 1508 pairs.\n",
        "- A random model would score 0.5, so all models here are worse than random, confirming systematic bias embedded in the pretraining data.\n",
        "- `EleutherAI/gpt-neo-125m` is the least biased overall at 0.46, while `gpt2` is the most biased at 0.42, but the gap between all models is narrow, suggesting bias at this scale is architecture-agnostic.\n",
        "- Sexual orientation is the most consistently biased category across all 5 models, with bias scores ranging from 0.75 to 0.80, meaning models prefer the stereotyped sentence 3 out of 4 times.\n",
        "- Nationality is the fairest category across all models, with `gpt-neo-125m` actually beating random at 0.61 fairness.\n",
        "- Socioeconomic, religion, and physical appearance show persistent bias across all models, suggesting these patterns are deeply embedded in pretraining corpora rather than being model-specific.\n",
        "- High transparency scores in notebook 02 do not translate to fairness, well-documented models are not necessarily fair ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ7coDTiZciP"
      },
      "source": [
        "**Next 04_robustness_score.ipynb**\n",
        "\n",
        "Measuring each model's resistance to adversarial word substitutions using TextAttack's TextFooler recipe on a sentiment classification task."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
